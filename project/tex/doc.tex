\documentclass[letterpaper,11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[spanish,mexico]{babel}
\usepackage{amsmath, amsthm,amssymb}
\usepackage[shortlabels]{enumitem}
\setenumerate{itemsep=0pt}
\usepackage{multicol,caption}
\usepackage[bottom=2.2cm, top=2.1cm,inner=2.0cm,outer=1.8cm]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{abstract}
%\renewcommand\refname{Bibliografía}
\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
\newenvironment{Table}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}

\begin{document}
\title{Proyecto de Aprendizaje Automatizado:\\
{\Large Un estudio sobre el uso del internet para comprar bienes}}
\author{Erick García Ramírez\footnote{
erick\_phy@ciencias.unam.mx, MCIC, IIMAS--UNAM.}}

\maketitle
\begin{abstract}
\noindent 
\end{abstract}

%\vspace{\baselineskip}
%{\noindent \bf Contenido}
%\begin{enumerate}
%    \item[1.] Introducción 
%    \item[2.] Antecedentes
%    \item[3.] Metodología
%    \item[4.] Resultados
%    \item[5.] Conclusiones
%    \item[6.] Referencias
%\end{enumerate}

\begin{multicols}{2}
\section{Introducción}
A lo largo de las últimas decadas las aplicaciones del Aprendizaje Automatizado han sido bastas y de
naturaleza muy diversa. Algunas de ellas, como lo son los Sistemas Automatizados de Recomendación y la Detección de
Operaciones Irregulares, tienen el objetivo de apoyar las actividades comerciales de empresas que ofertan
sus bienes y/o servicios por medio del internet. En este trabajo desarrollaremos una aplicación del Aprendizaje
Automatizado a este rubro.

Para una empresa que oferta algún producto o un servicio resulta muy valioso distinguir---de entre todas
las personas a las que dirige su publicidad---a aquellas personas que con mayor probabilidad comprarán o
contrarán su oferta. Determinar las características de los \emph{buenos clientes} y los \emph{malos clientes} es importante pues 
le a la empresa la oportunidad de optimizar sus estrategias de publicidad y de administración de clientes. 

Con la proliferación de grandes datos sobre el consumo de bienes y contratación de servicios, y en particular con la enorme
disponibilidad de datos de comercio en línea, las tareas de distinguir las características importantes de clientes es
una aplicación clásica y bien desarrollada de la Minería de Datos y el Aprendizaje Automatizado (\cite[Cap. I]{berry}).  

En el presente trabajo aplicaremos técnicas de Aprendizaje Automatizado a los datos de venta de un producto por parte de una empresa, 
con el objetivo de descubrir las características de las personas que con mayor probabilidad comprarán el producto. 


\section{Antecedentes}
El uso de la Minería de Datos y el Aprendizaje Automatizado para apoyar actividades comerciales tiene un impacto
importante y una larga tradición, vea por ejemplo \cite{berry}\cite{big}\cite{tdk}.  Dentro de este contexto, el 
\emph{perfilado de usuarios o clientes} es una de las tareas en que dichas disciplinas sobresalen.
\cite{faw}\cite{discov}\cite{mah}\cite{chen} y \cite{segmen} exploran la aplicación del aprendizaje automatizado al
perfilado de usarios o clientes.

Un \emph{perfil} es un conjunto de información que funge como representación de una persona, usuario o cliente\cite{cufo}. La información que
conforma un perfil puede ser de naturaleza diversa; puede incluir, por ejemplo, datos conductuales, rasgos físicos y rasgos
socio-económicos. La información que debe constituir un perfil típicamente se determina a partir del uso que
se desea dar a dicho perfil. Por ejemplo, un perfil de un candidato a ingresar a alguna universidad
incluye información sobre su rendimiento en niveles acádemicos precedentes, su rendimiento en exámenes de ingreso y, 
posiblemente, algunos datos sobre su contexto socio-económico. En este caso la información necesaria para un perfil es
especificada por el cómite encargado del proceso de selección de la universidad. 

En muchos otros contextos especificar la información que debe constituir un perfil no es tan sencillo como en
el ejemplo del párrrafo anterior. 

El siguiente es el ejemplo que abordaremos en este trabajo. Cuando una empresa tiene la intención de lanzar un nuevo
producto a la venta, o de simplemente mejorar la estrategia publicitaria sobre algún producto, 
hay un gran interés en determinar qué personas serán sus potenciales compradores, es decir, es importante descubrir el perfil de los compradores 
del producto. El descubrimiento exitoso de dicho perfil permitiría a la empresa diseñar una estrategia publicitaria adecuada
para maximizar sus ventas del producto. Sin embargo, puede resultar
complicado determinar por adelantado y con precisión cuáles serán los rasgos del perfil que más influirán en la decisión
de compra del producto. Frente a tal problema, el punto de vista más común en la actualidad es el de colectar la mayor información posible para
formar un perfil provisional, para posteriormente determinar un perfil más
preciso (en este caso, el perfil de las personas que con mayor probabilidad comprarán el producto). El  proceso de
determinar dicho perfil se lleva a cabo por medio de técnicas de Minería de Datos y Aprendizaje Automatizado. 

Entre las técnicas utilizadas para el perfilado de usuarios y/o clientes se encuentran los árboles de decisión,
los algoritmos de clustering y los  algoritmos de clasificación (vea \cite{mah}, donde  puede encontrar una tabla
comprensiva sobre las técnicas usadas para esta tarea). Cada uno de estas tiene cualidades o desventajas que las hacen valiosas o
inapropiadas dependiendo de sus requisitos y condiciones generales del problema. Los árboles de decisión tienen la característica de 
dar una buen panorama de las características del perfil, con
resultados interpretables de manera natural y de naturaleza cualitativa \cite[Cap. 6]{berry}. Los algoritmos de clustering ofrecen
una segmentación de los usuarios/clientes, subrayando aquellas características que les hacen ser similares. Los algoritmos de clasificación 
(e.g. máquinas de soporte vectorial y redes neuronales) al ser combinadas con alguna técnica de selección de variables
ofrecen también una forma de determinar los rasgos importantes de un perfil. A menudo, en combinación, estas y otras
técnicas ayudan en la tarea de determinar el perfil más útil.

\section{Metodología}
El conjunto de datos que usaremos en este trabajo es \emph{Individual Company Sales Data}, disponible en www.kaggle.com~
\cite{kaggle}. Los datos corresponden a las ventas por internet de un producto por parte de una 
empresa\footnote{El conjunto se presenta anonimizado, no se conoce ni el producto ni el nombre de la empresa}. Cada
renglón en el conjunto corresponde a la información de un cliente.  Se colectaron 14 datos sobre el cliente y una bandera
que señala si el cliente compró el producto o no. Después de remover aquellos renglones en los que hay algún valor
no conocido de algún atributo, el conjunto consta de 23558 muestras. La tabla~\ref{tab:1} describe la estructura y 
naturaleza del conjunto de datos.

Ya que la naturaleza de los datos es mixta, es decir, hay tanto datos númericos como categórico
debemos comentar sobre la preparación y el preprocesamiento de ellos. Se tomaron los siguientes pasos de manera
consecutiva. 

\begin{enumerate}[I.]
    \item Todos aquellos atributos de tipo categórico ordinal se cambiaron directamente por números en $[0,1]$
        (e.g., en fam\_income `A' corresponde a 0.0 y `L' a 1.0). 
    \item house\_val se re-escaló al intervalo [0,1]. 
    \item Para aquellos atributos categóricos binarios (e.g., `gender') se cambiaron los valores originales a 1 y 0. 
    \item Para aquellos atributos de tipo categórico nominal que no son binarios se aplicó one-hot-encoding (sin
            embargo, el punto donde esto se hace depende de la técnica de aprendizaje con la que se trabaja, vea el
        código asociado\footnote{github}). 
\end{enumerate}
%Comenzamos el trabajo sobre este conjunto de datos con un minado superficial de datos (describiremos a grandes rasgos
%la distribución de cada valor de los atributos). 
Se realizaron las siguientes tareas de Aprendizaje Automatizado el sobre conjunto de datos.

\begin{itemize}
    \item[(a)] Se halla el subconjunto de atributos \emph{más significativos} mediante un modelo de regresión logística
        y forward-selection~\cite[Cap. 6]{book1}.
    \item[(b)] Se aplica un Análisis de Componentes Principales PCA \cite{book2} y posteriormente se ajusta un modelo de regresión
        logística (seleccionado mediante validación cruzada). 
    \item[(c)] Se explora la segmentación de los clientes por medio de clustering (K-means) \cite{segmen}.
\end{itemize}
\end{multicols}

\begin{table}
\begin{center}
\scalebox{0.85}{
\begin{tabular}{|c|c|c|p{10cm}|}
    \hline
    \bf Columna & \bf Atributo & \bf Tipo de dato & \bf\hspace{2.5cm} Valores\\
    \hline 
    0 &\bf flag & categórico nominal &  Y, N si compró el producto, {\footnotesize(56.6\% y 43.4\% resp.)} \\
    \hline 
    1 &\bf  gender & categórico nominal & F, M  {\footnotesize (39\% y 61\% resp.)}\\
    \hline
    2 &\bf education & categórico ordinal & 0.lessHS, 1.HS, 2.SomeCollege, 3.Bach,
    4.Grad {\footnotesize (8.7\%, 21.4\%, 27.8\%, 25.4\% y 16.6\% resp.)}  \\ 
    \hline 
    3 &\bf house\_val & númerico & en [0, 999999]\\
    \hline 
    4 &\bf age & categórico nominal & 1\_Unk, 2upto25, 3upto35, 4upto45,
     5upto55, 6upto65, 7above65 {\footnotesize(13\%, 2.5\%, 10.7\%, 21.1\%, 25.8\%, 16.9\% y 9.8\% resp.)}\\ 
    \hline 
    5 &\bf online & categórico nominal &  Y, N el cliente tiene experiencia en compras por interne{\footnotesize (70.1\% y 29.9\% resp.)}; \\
    \hline
    6 &\bf  customer\_psy & categórico nominal & A--J, psicología del cliente, basaso en área de residencia  {\footnotesize (3.4\%, 21.9\%, 
            22.3\%, 5.6\%, 15.9\%, 9.3\%, 9.9\%, 1.6\%, 4.9\% y  5.1\% resp.)} \\
    \hline
    7 &\bf marriage & categórico nóminal & Y, N {\footnotesize (81.8\% y 18.2\% resp.)}\\
    \hline
    8 &\bf children & categórico nominal & Y, N, U {\footnotesize (31\%, 47\% y 21\% resp.)} \\
    \hline 
    9 &\bf occupation & categórico nominal & Professional, Blue Collar, Retired, SalesService,
    Others, Farm {\footnotesize (41.7\%, 16.9\%, 8.6\%, 28.2\%, 3.9\% y 0.7\% resp.)}\\
    \hline 
    10 &\bf  mortgage & categórico nominal & 1Low, 2Med,  3High {\footnotesize (69.9\%, 13.7\% y 16.3\% resp.)}\\
    \hline 
    11 &\bf house\_owner & categórico nominal & Owner, Renter {\footnotesize (79.7\% y 20.3\% resp.)}\\
    \hline 
    12 &\bf region & categórico nominal & West, South, Midwest, Northeast, Rest {\footnotesize (21.8\%, 39\%, 20.7\%,
    17.8\% y 0.6\% resp.)}\\
    \hline 
    13 &\bf car\_prob & categórico ordinal & 1--9; probabilidad de que comprará un auto nuevo {\footnotesize (32.1\%,
    18.8\%, 13.4\%, 7.1\%, 6.6\%, 5\%, 4.8\%, 6.3\% y 5.8\% resp.)}\\
    \hline 
    14 &\bf fam\_income & categórico ordinal & A--L; nivel del ingreso familiar, L es el más alto {\footnotesize (5\%,
    4.8\%, 5.7\%, 10.5\%, 20.7\%, 17.4\%, 11\%, 6.8\%, 4.6\%, 4.6\%, 4.1\% y 4.6\% resp.)}\\
    \hline
\end{tabular}}
\end{center}
\caption{\small La estructura de la base de datos.}
\label{tab:1}
\end{table}

\begin{multicols}{2}
\section{Resultados}
El conjunto de 23558 renglones se particionó en un conjunto de entrenamiento y otro de prueba con la
proporción 70--30\%. En (a) y (b) se trabaja con el conjunto de entrenamiento para la selección de variables. El
conjunto de prueba se usa únicamente para observar la bondad del mejor modelo encontrado con respecto a predicciones
sobre muestras nuevas. 
\subsubsection*{(a) \emph{Forward-Selection} y regresión logística}
El método de forward-selection\cite{book1} halla iterativamente el mejor modelo considerando desde uno hasta el total de atributos
(en nuestro caso, hasta 14 atributos). El método funciona partiendo de algún
modelo de clasificación, que en nuestro caso será el de regresión logística. También se requiere fijar el criterio
para comparar los diferentes modelos; para nosotros este criterio será el de mayor área bajo la curva ROC (AUC). 

\begin{Figure}
    \centering
    \includegraphics[width=1\textwidth]{AUC}
    \captionof{figure}{\em \footnotesize Área bajo la curva ROC contra número de variables consideradas}
    \label{fig:auc}
\end{Figure}
La figura~\ref{fig:auc} muestra el comportamiento de AUC con respecto al número de variables consideradas. Se puede
observar (y analizar numéricamente) que la AUC aumenta significativamente desde 1 hasta 8 atributos, pero su crecimiento
se desacelera para más de 8 atributos. La figura~\ref{fig:score} soporta esta elección pues muestra que el score de los modelos varia de una
forma similar con respecto al número de atributos.
\begin{Figure}
    \includegraphics[width=1\textwidth]{Score}
\captionof{figure}{\em \small Score (para regresión logística) contra número de variables consideradas.}
\label{fig:score}
\end{Figure}
 Por lo tanto, tomamos como subconjunto de \emph{atributos más
importantes} a los 8 atributos que forward-selection halló considerando 8 atributos. Los atributos son:
\begin{center} \em customer\_psy, age, education, online, gender, 
car\_prob, mortgage, occupation
\end{center}
El modelo de regresión logística correspondiente alcanza un score de 0.706 sobre el conjunto de prueba. La matriz de
confusión sobre
el conjunto de prueba es:
\[\begin{bmatrix}
        & Predicted 0 & Predicted  1 \\
   True 0 & 1830 & 1275\\
   True 1 & 801 &3162
 \end{bmatrix}\]
 Adicionalmente, forward-selection da una idea de cuáles son los $n$ atributos más importantes para cada
$n\leq 14$, vea la tabla~\ref{tab:fs}. 

\begin{Table}
\begin{center}
\scalebox{0.8}{
\begin{tabular}{|c|c|c|}
    \hline 
    $n$ & $n$ atr. más importantes & AUC \\
    \hline
    1 & customer\_psy & 0.626\\
    \hline
    2 &  age & 0.640\\
    \hline
    3 & education & 0.651\\
    \hline 
    4 & online & 0.659\\
    \hline
    5 & gender & 0.671\\
    \hline 
    6 & car\_prob& 0.675\\
    \hline
    7 & mortgage & 0.678\\
    \hline
    \bf 8 & \bf occupation &\bf 0.681\\
    \hline
    9 & child & 0.682\\
    \hline
    10 & house\_val & 0.682\\
    \hline
    11 & house\_owner & 0.682\\
    \hline
    12 & fam\_income & 0.681\\
    \hline
    13 & region & 0.682\\
    \hline
    14 & \emph{todas} & 0.684\\
    \hline
\end{tabular}}
\captionof{table}{\small \em Los $n$ atributos más importantes. La columnas 2 y 3 son acumulativas hacia abajo.}
\label{tab:fs}
\end{center}
\end{Table}


\subsubsection*{(b) PCA y regresión logística}
El Ánalisis de Componentes Principales (PCA) es una técnica empleada para reducir la dimensionalidad de un conjunto de
datos. PCA identifica los ejes en el espacio n-dimensional sobre los cuales el conjunto de datos tiene más variabilidad.
Aunque PCA ayuda a eliminar algunos atributos (los que no añaden mucha información, i.e. varianza, al conjunto de datos)
es casi siempre díficil interpretar su resultado. No es fácil extraer cuáles fueron los atributos que PCA eliminó. 
Su valor en nuestro caso, es verificar si después de su aplicación, PCA mejora las cualidades de un modelo de regresión
logística.

Despues de aplicar one-hot-encoding al conjunto de datos de entrenamiento se cuenta con 51 columnas de
atributos. Se aplica PCA para reducir su dimensionalidad. Aplicamos la versión PCA(A) donde $A\in (0,1)$ es la cantidad
de varianza que deseamos cubrir al reducir la dimensión. Por ejemplo, para $A=0.85$ se pasa de 42 dimensiones a sólo 18.
Para cada valor de $A$, se genera la matriz (de dimensión reducida) y con ella se encuentra el mejor modelo de regresión
logística seleccionado por validación cruzada (\emph{10-fold}). Comparamos los modelos obtenidos por su AUC. 
La figura~\ref{fig:pca} muestra el comportamiento de los modelos generados. 







\subsubsection*{(c) Segmentación vía Clustering} 
Aplicamos el algoritmo K-means~\cite[Cap. 13]{book2}.
\section{Conclusiones}

\begin{thebibliography}{10}
        {\small 
    \bibitem{berry} M. Berry y G. Linoff. {\em Data Mining Techniques For Marketing, Sales, and Customer Relationship Management.} 
        2da Edición. Wiley Publishing Inc., 2004. 
    \bibitem{big} J. Dean. {\em Big Data, Data Mining, and Machine Learning: Value Creation for Business, Leaders and
        Practitioners}. John Wiley  Sons, 2014.
    \bibitem{tdk} TDK-technologies. {\em Business Intelligence, Data Mining and Machine Learning.} 
        Disponible en: \url{www.tdktech.com/tech-talks/business-intelligence-data-mining%-machine-learning}. 
        \bibitem{cufo} A. Cufoglu. {\em User Profiling-A Short Review}. International Journal of Computer Applications,
        Volume 108-- No. 3, 2014.
    \bibitem{faw} T. Fawcett y P. Foster. {\em Combining Data Mining and Machine Learning for Effective User
        Profiling.} En KDD-96 Proceedings, págs. 8-13, AAAI, 1996.
    \bibitem{discov} A. Bellogín, I. Cantador, P. Castells y Á. Ortigosa. {\em Discovering Relevant Preferences in a Personalised
        Recommender System using Machine Learning Techniques}, en Preference Learning Workshop, en la 8th
        European Conference on Machine  Learning and Principles and Practice of Knowledge Discovery in Databases, 2008. 
    \bibitem{mah} M. Harandi. {\em User Profiling in News Recommender Systems}. Disponible en:
        \url{https://www.ntnu.no/wiki/download/attachments/86731314/User%20Profiling%20NRS.pdf?version%3}
    \bibitem{chen} Q. Chen, A. Norcio y J. Wang. {\em Neural Network Based Stereotyping for User Profiles}. Neural
        Computing and Applications No. 9, págs. 259--265,  2000.
    \bibitem{kaggle} {\em Individual Company Sales Data.} Disponible en:
        \url{https://www.kaggle.com/mickey1968/individual-company-sales-data}. 
    \bibitem{segmen} K. Kashwan y C. Velu. {\em Customer Segmentation Using Clustering and Data Mining Techniques}. International Journal of Computer Theory 
        and Engineering, Vol. 5 (6), págs. 856--860, 2013. 
    \bibitem{book2} M. Zaki y W. Meira. {\em Data minining and Analysis}. Cambridge University Press, 2014. 
    \bibitem{book1} G. James, D. Witten, T. Hastie y R. Tibshirani. {\em An Introduction to Statistical Learning}.
        Springer 2013.
    }
\end{thebibliography}
\end{multicols}
\end{document}

