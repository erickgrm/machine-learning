\documentclass[letterpaper,11pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[spanish,mexico]{babel}
\usepackage{amsmath, amsthm,amssymb}
\usepackage[shortlabels]{enumitem}
\setenumerate{itemsep=0pt}
\usepackage{multicol,caption}
\usepackage[bottom=2.2cm, top=2.1cm,inner=2.0cm,outer=1.8cm]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks=true}
\PassOptionsToPackage{hyphens}{url}\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{abstract}
%\renewcommand\refname{Bibliografía}
\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
\newenvironment{Table}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}
  \providecommand{\keywords}[1]{\textbf{\small \textit{Keywords:}} {\small\em #1}}
\begin{document}
\title{Proyecto de Aprendizaje Automatizado:\\
{\Large Un estudio sobre el uso del internet para comprar bienes}}
\author{Erick García Ramírez\footnote{
erick\_phy@ciencias.unam.mx, MCIC, IIMAS--UNAM.}}

\maketitle
\begin{abstract}
    \noindent Presentamos una aplicación del Aprendizaje Automatizado y la Minería de Datos al comercio en línea, en
    particular al problema de determinar el perfil de un cliente. El conjunto de datos considerado contiene la
    información de los clientes de una empresa, para los cuales deseamos identificar los rasgos 
    más importantes que determinan si comprarán el producto ofertado por la empresa. Para esta tarea empleamos las técnicas de
\emph{one-step forward-selection} y regresión logística.  Posteiormente aplicamos el algoritmo de clustering KModes para
segmentar el conjunto de clientes. Indicamos como un análisis más detallado de los clusters permitiría especificar 
las características de los clientes que con mayor probabilidad comprarán el producto.
\end{abstract}
\keywords{E-commerce, regresión logística, forward-selection, datos mixtos, clustering, KModes}

\vspace{\baselineskip}

\begin{multicols}{2}
\section{Introducción}
A lo largo de las últimas décadas las aplicaciones del Aprendizaje Automatizado han sido bastas y de
naturaleza muy diversa. Algunas de ellas, como lo son los Sistemas Automatizados de Recomendación y la Detección de
Operaciones Irregulares, tienen el objetivo de apoyar a las actividades comerciales de empresas que ofertan
sus bienes y/o servicios por medio del internet. En este trabajo desarrollaremos una aplicación del Aprendizaje
Automatizado a este rubro.

Para una empresa que oferta algún producto o un servicio resulta muy valioso distinguir---de entre todas
las personas a las que dirige su publicidad---a aquellas personas que con mayor probabilidad comprarán o
contrarán su oferta. Determinar las características de los \emph{buenos clientes} y los \emph{malos clientes} es importante pues 
le da a la empresa la oportunidad de optimizar sus estrategias de publicidad y de administración de sus clientes. 

Con la proliferación de grandes datos sobre el consumo de bienes y contratación de servicios, y en particular con la enorme
disponibilidad de datos de comercio en línea, las tareas de distinguir las características importantes de clientes es
una aplicación clásica y bien desarrollada de la Minería de Datos y el Aprendizaje Automatizado (\cite[Cap. I]{berry}).  

En el presente trabajo aplicaremos técnicas de Aprendizaje Automatizado a los datos de venta de un producto por parte de una empresa, 
con el objetivo de descubrir las características de las personas que con mayor probabilidad comprarán el producto. 


\section{Antecedentes}
El uso de la Minería de Datos y el Aprendizaje Automatizado para apoyar actividades comerciales tiene un impacto
importante y una larga tradición, vea por ejemplo \cite{berry}\cite{big}.  Dentro de este contexto, el 
\emph{perfilado de usuarios o clientes} es una de las tareas en que dichas disciplinas sobresalen.
\cite{faw}\cite{discov}\cite{mah}\cite{chen} y \cite{segmen} exploran la aplicación del aprendizaje automatizado al
perfilado de usarios o clientes.

Un \emph{perfil} es un conjunto de información que funge como representación de una persona, usuario o cliente\cite{cufo}. La información que
conforma un perfil puede ser de naturaleza diversa; puede incluir, por ejemplo, datos conductuales, rasgos físicos y/o rasgos
socio-económicos. La información que debe constituir un perfil típicamente se determina a partir del uso que
se desea dar a dicho perfil. Por ejemplo, un perfil de un candidato a ingresar a alguna universidad
incluye información sobre su rendimiento en niveles acádemicos precedentes, su rendimiento en exámenes de ingreso y, 
posiblemente, algunos datos sobre su contexto socio-económico. En este caso la información necesaria para un perfil es
especificada por el cómite encargado del proceso de selección de la universidad. 

En muchos otros contextos especificar la información que debe constituir un perfil no es tan sencillo como en
el ejemplo del párrrafo anterior. 

El siguiente es el ejemplo que abordaremos en este trabajo. Cuando una empresa tiene la intención de lanzar un nuevo
producto a la venta, o de simplemente mejorar la estrategia publicitaria sobre algún producto, 
hay un gran interés en determinar qué personas serán sus potenciales compradores, es decir, es importante descubrir el perfil de los compradores 
del producto. El descubrimiento exitoso de dicho perfil permitiría a la empresa diseñar una estrategia publicitaria adecuada
para maximizar sus ventas del producto. Sin embargo, puede resultar
complicado determinar por adelantado y con precisión cuáles serán los rasgos del perfil que más influirán en la decisión
de compra del producto. Frente a tal problema, el punto de vista más común en la actualidad es el de colectar la mayor información posible para
formar un perfil provisional, para posteriormente determinar un perfil más
preciso (en este caso, el perfil de las personas que con mayor probabilidad comprarán el producto). 

Entre las técnicas de Minería de Datos y Aprendizaje Automatizado
utilizadas para el perfilado de usuarios y/o clientes se encuentran los árboles de decisión,
los algoritmos de clustering y los  algoritmos de clasificación (vea \cite{mah}, donde  puede encontrar una tabla
comprensiva sobre las técnicas usadas para esta tarea). Cada uno de estas tiene cualidades o desventajas que las hacen valiosas o
inapropiadas dependiendo de sus requisitos y condiciones generales del problema. Los árboles de decisión tienen la característica de 
dar una buen panorama de las características del perfil, con
resultados interpretables de manera natural y de naturaleza cualitativa \cite[Cap. 6]{berry}. Los algoritmos de clustering ofrecen
una segmentación de los usuarios/clientes, subrayando aquellas características que les hacen ser similares. Los algoritmos de clasificación 
(e.g. máquinas de soporte vectorial y redes neuronales) al ser combinadas con alguna técnica de selección de variables
ofrecen también una forma de determinar los rasgos importantes de un perfil. A menudo, en combinación, estas y otras
técnicas ayudan en la tarea de determinar el perfil más útil.
%\end{multicols}


\begin{table*}[t]
\begin{center}
\scalebox{0.85}{
\begin{tabular}{|c|c|c|p{10cm}|}
    \hline
    \bf Columna & \bf Atributo & \bf Tipo de dato & \bf\hspace{2.5cm} Valores\\
    \hline 
    0 &\bf flag & categórico nominal &  Y, N si compró el producto, {\footnotesize(56.6\% y 43.4\% resp.)} \\
    \hline 
    1 &\bf  gender & categórico nominal & F, M  {\footnotesize (39\% y 61\% resp.)}\\
    \hline
    2 &\bf education & categórico ordinal & 0.lessHS, 1.HS, 2.SomeCollege, 3.Bach,
    4.Grad {\footnotesize (8.7\%, 21.4\%, 27.8\%, 25.4\% y 16.6\% resp.)}  \\ 
    \hline 
    3 &\bf house\_val & númerico & en [0, 999999]\\
    \hline 
    4 &\bf age & categórico nominal & 1\_Unk, 2upto25, 3upto35, 4upto45,
     5upto55, 6upto65, 7above65 {\footnotesize(13\%, 2.5\%, 10.7\%, 21.1\%, 25.8\%, 16.9\% y 9.8\% resp.)}\\ 
    \hline 
    5 &\bf online & categórico nominal &  Y, N el cliente tiene experiencia en compras por interne{\footnotesize (70.1\% y 29.9\% resp.)}; \\
    \hline
    6 &\bf  customer\_psy & categórico nominal & A--J, psicología del cliente, basaso en área de residencia  {\footnotesize (3.4\%, 21.9\%, 
            22.3\%, 5.6\%, 15.9\%, 9.3\%, 9.9\%, 1.6\%, 4.9\% y  5.1\% resp.)} \\
    \hline
    7 &\bf marriage & categórico nóminal & Y, N {\footnotesize (81.8\% y 18.2\% resp.)}\\
    \hline
    8 &\bf children & categórico nominal & Y, N, U {\footnotesize (31\%, 47\% y 21\% resp.)} \\
    \hline 
    9 &\bf occupation & categórico nominal & Professional, Blue Collar, Retired, SalesService,
    Others, Farm {\footnotesize (41.7\%, 16.9\%, 8.6\%, 28.2\%, 3.9\% y 0.7\% resp.)}\\
    \hline 
    10 &\bf  mortgage & categórico nominal & 1Low, 2Med,  3High {\footnotesize (69.9\%, 13.7\% y 16.3\% resp.)}\\
    \hline 
    11 &\bf house\_owner & categórico nominal & Owner, Renter {\footnotesize (79.7\% y 20.3\% resp.)}\\
    \hline 
    12 &\bf region & categórico nominal & West, South, Midwest, Northeast, Rest {\footnotesize (21.8\%, 39\%, 20.7\%,
    17.8\% y 0.6\% resp.)}\\
    \hline 
    13 &\bf car\_prob & categórico ordinal & 1--9; probabilidad de que comprará un auto nuevo {\footnotesize (32.1\%,
    18.8\%, 13.4\%, 7.1\%, 6.6\%, 5\%, 4.8\%, 6.3\% y 5.8\% resp.)}\\
    \hline 
    14 &\bf fam\_income & categórico ordinal & A--L; nivel del ingreso familiar, L es el más alto {\footnotesize (5\%,
    4.8\%, 5.7\%, 10.5\%, 20.7\%, 17.4\%, 11\%, 6.8\%, 4.6\%, 4.6\%, 4.1\% y 4.6\% resp.)}\\
    \hline
\end{tabular}}
\end{center}
\caption{\small La estructura de la base de datos.}
\label{tab:1}
\end{table*}

\section{Metodología}
El conjunto de datos que usaremos en este trabajo es \emph{Individual Company Sales Data}, disponible en www.kaggle.com~
\cite{kaggle}. Los datos corresponden a las ventas por internet de un producto por parte de una 
empresa\footnote{El conjunto se presenta anonimizado, no se conoce ni el producto ni el nombre de la empresa}. Cada
renglón en el conjunto corresponde a la información de un cliente.  Se colectaron 14 datos sobre el cliente y una bandera
que señala si el cliente compró el producto o no. Después de remover aquellos renglones en los que hay algún valor
no conocido de algún atributo, el conjunto consta de 23558 muestras. La tabla~\ref{tab:1} describe la estructura y 
naturaleza del conjunto de datos.

Ya que la naturaleza de los datos es mixta, es decir, hay tanto datos númericos como categóricos
debemos comentar sobre la preparación y el preprocesamiento de ellos. Se tomaron los siguientes pasos de manera
consecutiva. 

\begin{enumerate}[I.]
    \item Todos aquellos atributos de tipo categórico ordinal se cambiaron directamente por números en $[0,1]$
        (e.g., en fam\_income `A' corresponde a 0.0 y `L' a 1.0). 
    \item house\_val se re-escaló al intervalo [0,1]. 
    \item Para aquellos atributos categóricos binarios (e.g., `gender') se cambiaron los valores originales a 1 y 0. 
    \item Para aquellos atributos de tipo categórico nominal que no son binarios se aplicó one-hot-encoding (sin
            embargo, el punto donde esto se hace depende de la técnica de aprendizaje con la que se trabaja, vea el
        código asociado\footnote{github}). 
\end{enumerate}
%Comenzamos el trabajo sobre este conjunto de datos con un minado superficial de datos (describiremos a grandes rasgos
%la distribución de cada valor de los atributos). 
Se realizaron las siguientes tareas de Aprendizaje Automatizado el sobre conjunto de datos.

\begin{itemize}
    \item[(a)] Se halla el subconjunto de atributos \emph{más significativos} mediante un modelo de regresión logística
        y forward-selection~\cite[Cap. 6]{book1}.
    \item[(b)] Se aplica un Análisis de Componentes Principales PCA \cite{book2} y posteriormente se ajusta un modelo de regresión
        logística (seleccionado mediante validación cruzada). 
    \item[(c)] Se explora la segmentación de los clientes por medio de clustering (K-modes) \cite{kmodes}.
\end{itemize}

\section{Resultados}
El conjunto de 23558 renglones se particionó en un conjunto de entrenamiento y otro de prueba con la
proporción 70--30\%. En (a) y (b) se trabaja con el conjunto de entrenamiento para la selección de variables. El
conjunto de prueba se usa únicamente para observar la bondad del mejor modelo encontrado con respecto a predicciones
sobre muestras nuevas. 
\subsubsection*{(a) \emph{Forward-Selection} y regresión logística}
El método de forward-selection\cite{book1} halla iterativamente el mejor modelo considerando desde uno hasta el total de atributos
(en nuestro caso, hasta 14 atributos). El método funciona partiendo de algún
modelo de clasificación, que en nuestro caso será el de regresión logística. También se requiere fijar el criterio
para comparar los diferentes modelos; para nosotros este criterio será el de mayor área bajo la curva ROC (AUC). 

\begin{Figure}
    \centering
    \includegraphics[width=1\textwidth]{AUC}
    \captionof{figure}{\em \footnotesize Área bajo la curva ROC contra número de variables consideradas}
    \label{fig:auc}
\end{Figure}
La figura~\ref{fig:auc} muestra el comportamiento de AUC con respecto al número de variables consideradas. Se puede
observar (y analizar numéricamente) que la AUC aumenta significativamente desde 1 hasta 8 atributos, pero su crecimiento
se desacelera para más de 8 atributos. La figura~\ref{fig:score} soporta esta elección pues muestra que el score de los modelos varia de una
forma similar con respecto al número de atributos.
\begin{Figure}
    \includegraphics[width=1\textwidth]{Score}
\captionof{figure}{\em \small Score (para regresión logística) contra número de variables consideradas.}
\label{fig:score}
\end{Figure}
 Por lo tanto, tomamos como subconjunto de \emph{atributos más
importantes} a los 8 atributos que forward-selection halló considerando 8 atributos. Los atributos son:
\begin{center} \em customer\_psy, age, education, online, gender, 
car\_prob, mortgage, occupation
\end{center}
El modelo de regresión logística correspondiente alcanza un score de 0.706 sobre el conjunto de prueba. La matriz de
confusión sobre
el conjunto de prueba es:
\[\begin{bmatrix}
        & Predicted 0 & Predicted  1 \\
   True 0 & 1830 & 1275\\
   True 1 & 801 &3162
 \end{bmatrix}\]
 Adicionalmente, forward-selection da una idea de cuáles son los $n$ atributos más importantes para cada
$n\leq 14$, vea la tabla~\ref{tab:fs}. 

\begin{Table}
\begin{center}
\scalebox{0.8}{
\begin{tabular}{|c|c|c|}
    \hline 
    $n$ & $n$ atr. más importantes & AUC \\
    \hline
    1 & customer\_psy & 0.626\\
    \hline
    2 &  age & 0.640\\
    \hline
    3 & education & 0.651\\
    \hline 
    4 & online & 0.659\\
    \hline
    5 & gender & 0.671\\
    \hline 
    6 & car\_prob& 0.675\\
    \hline
    7 & mortgage & 0.678\\
    \hline
    \bf 8 & \bf occupation &\bf 0.681\\
    \hline
    9 & child & 0.682\\
    \hline
    10 & house\_val & 0.682\\
    \hline
    11 & house\_owner & 0.682\\
    \hline
    12 & fam\_income & 0.681\\
    \hline
    13 & region & 0.682\\
    \hline
    14 & \emph{todas} & 0.684\\
    \hline
\end{tabular}}
\captionof{table}{\small \em Los $n$ atributos más importantes. La columnas 2 y 3 son acumulativas hacia abajo.}
\label{tab:fs}
\end{center}
\end{Table}


\subsubsection*{(b) PCA y regresión logística}
El Ánalisis de Componentes Principales (PCA) es una técnica empleada para reducir la dimensionalidad de un conjunto de
datos. PCA identifica los ejes en el espacio n-dimensional sobre los cuales el conjunto de datos tiene más variabilidad.
Aunque PCA ayuda a eliminar algunos atributos (los que no añaden mucha información, i.e. varianza, al conjunto de datos)
es casi siempre díficil interpretar su resultado. No es fácil extraer cuáles fueron los atributos que PCA eliminó. 
Su valor en nuestro caso, es verificar si después de su aplicación, PCA mejora las cualidades de un modelo de regresión
logística.

Despues de aplicar one-hot-encoding al conjunto de datos de entrenamiento se cuenta con 42 columnas de
atributos. Se aplica PCA para reducir su dimensionalidad. Aplicamos la versión PCA(A) donde $A\in (0,1)$ es la cantidad
de varianza que deseamos cubrir al reducir la dimensión. Por ejemplo, para $A=0.85$ se pasa de 42 dimensiones a sólo 18.
Para cada valor de $A$, se genera la matriz (de dimensión reducida) y con ella se encuentra el mejor modelo de regresión
logística seleccionado por validación cruzada (\emph{10-fold}). Comparamos los modelos obtenidos por su AUC. 
La figura~\ref{fig:pca} muestra el comportamiento de la AUC de los modelos generados con respecto a $A$.  

\begin{Figure}
    \centering
    \includegraphics[width=1\textwidth]{PCA}
    \captionof{figure}{\em \footnotesize Área bajo la curva ROC contra proporción de varianza $A$ explicada por PCA}
    \label{fig:pca}
\end{Figure}
La máxima AUC se alcanza para $A=0.95$ y para tal valor la dimensión se redujó de 42 a 26. Para lograr un balance entre
maximizar AUC y disminuir la dimensión lo más posible, proponemos tomar como mejor modelo a aquel correspondiente a
$A=0.90$. 

Para $A=0.90$ la dimensión se redujó de 42 a 21, y el AUC alcanzado es de 0.677. Para el modelo de regresión logística
correspondiente, el score sobre el conjunto de prueba es de 0.701 y la matriz de confusión sobre el conjunto de prueba
es:

\[\begin{bmatrix}
        & Predicted 0 & Predicted  1 \\
   True 0 & 1833 & 1272\\
   True 1 & 843 &3120
 \end{bmatrix}\]


\subsubsection*{(c) Segmentación vía Clustering} 
Aplicamos el algoritmo K-modes, el cual es un algoritmo de clustering basado en K-means pero que está diseñado para
poder ser usado con conjuntos de datos mixtos\cite{kmodes}. Usaremos el conjunto de datos limitado al conjunto de atributos más
importantes descubierto en (a). 

Investigamos el resultado de  segmentar a los clientes en dos clusters, buscando capturar los grupos 
`flag' = 1 y `flag= 0' (i.e., separar compradores de no compradores). Se ejecutó Kmodes en cinco ocasiones obteniéndose 126657.0
el menor valor de costo\footnote{En KModes la función de costo está determinada como una combinación de la distancia
    Euclidiana entre atributos númericos y una medida de similaridad entre atributos categóricos, vea\cite[Sec.
2.2]{kmodes}.}. Dicho valor genera dos clusters identificados por las etiquetas 0 y 1. Para juzgar si esta segmentación
refleja de alguna forma la división buscada en compradores y no compradores, podemos comparar el etiquetado del
clustering contra la columna 'flag' (n.b. recuerde que el etiquetado en clustering no es siempre el mismo sobre
    diferentes ejecuciones; en este punto se debe checar cómo se corresponden 1 y 0 del etiquetado del
clustering con el 1 y 0 de 1flag').

Los clusters obtenidos por KModes (usando los 8 atributos más importantes) etiquetan correctamente a 14428 de las
muestras, mientras que se equivocan en las 9130  restantes. Esto da un rendimiento (score) para KModes de 0.612.

\section{Conclusiones}
Por medio de forward-selection y regresión logística hallamos que para determinar si un cliente comprará el producto que
ofrece la empresa basta considerar los 8 atributos
\begin{center} \em customer\_psy, age, education, online, gender, 
car\_prob, mortgage, occupation
\end{center}
Estos son los atributos que constituyen el perfil de un cliente. Dado un cliente nuevo, la empresa debe colectar los
valores de estos atributos para posteriormente hacer una predicción sobre si el cliente comprará el producto o no usando el 
modelo entrenado para este trabajo. En 
La tabla~\ref{tab:fs} también puede orientar la decisión de qué atributos considerar si por alguna razón no se cuenta
con todos los 8 mejores. 

En (c) se aplicó la técnica de clustering considerando únicamente los 8 atributos más importantes. Un análisis
exploratorio  de los clusters resultantes, y la prueba con segmentaciones en más de dos clusters, determinaría cuáles
valores específicos de los atributos maximizan la probabilidad de que un cliente dado comprará el producto. El resultado
de tal análisis podrá entonces ser usado para mejorar la estrategia publicitaria del producto.

En el presente trabajo hemos mostrado un ejemplo de cómo se pueden aplicar algunas técnicas de Aprendizaje Automatizado
a un problema de comercio en línea. La extensión está aplicación puede tomar muchas direcciones. En el aspecto técnico,
algunas modificaciones al trabajo aquí presentado incluyen:

\begin{enumerate}
    \item[(i)] Usar la técnica \emph{best-subset}\cite[Cap. 6]{book1} en vez de forward-selection en (a). Esta
        última  no explora todos los $2^{14}-1$ subconjuntos de atributos posibles. La desventaja es que la
        complejidad del algoritmo se vuelve entonces exponencial. 
    \item[(ii)] Considerar otros modelos de clasificación para reemplazar a la regresión logística en (a)\footnote{
        Preliminarmente se consideró máquinas de soporte vectorial, pero su desempeño no fue considerablemente mejor y
    su entrenamiento es muy lento.}. 
    \item[(iii)] Para (c), aplicar la técnica CENG\cite{kuri} para codificar numéricamente todos los atributos de tipo
        categórico. CENG propone hacer esto minimizando la probabilidad de modificar los patrones (covarianzas) originales 
        en el conjunto de datos.
\end{enumerate}
\begin{thebibliography}{10}
        {\small 
    \bibitem{berry} M. Berry y G. Linoff. {\em Data Mining Techniques For Marketing, Sales, and Customer Relationship Management.} 
        2da Edición. Wiley Publishing Inc., 2004. 
    \bibitem{big} J. Dean. {\em Big Data, Data Mining, and Machine Learning: Value Creation for Business, Leaders and
        Practitioners}. John Wiley  Sons, 2014.
        \bibitem{cufo} A. Cufoglu. {\em User Profiling-A Short Review}. International Journal of Computer Applications,
        Volume 108-- No. 3, 2014.
    \bibitem{faw} T. Fawcett y P. Foster. {\em Combining Data Mining and Machine Learning for Effective User
        Profiling.} En KDD-96 Proceedings, págs. 8-13, AAAI, 1996.
    \bibitem{discov} A. Bellogín, I. Cantador, P. Castells y Á. Ortigosa. {\em Discovering Relevant Preferences in a Personalised
        Recommender System using Machine Learning Techniques}, en Preference Learning Workshop, en la 8th
        European Conference on Machine  Learning and Principles and Practice of Knowledge Discovery in Databases, 2008. 
    \bibitem{mah} M. Harandi. {\em User Profiling in News Recommender Systems}. Disponible en:
        \url{https://www.ntnu.no/wiki/download/attachments/86731314/User%20Profiling%20NRS.pdf?version%3}
    \bibitem{chen} Q. Chen, A. Norcio y J. Wang. {\em Neural Network Based Stereotyping for User Profiles}. Neural
        Computing and Applications No. 9, págs. 259--265,  2000.
    \bibitem{kaggle} {\em Individual Company Sales Data.} Disponible en:
        \url{https://www.kaggle.com/mickey1968/individual-company-sales-data}. 
    \bibitem{segmen} K. Kashwan y C. Velu. {\em Customer Segmentation Using Clustering and Data Mining Techniques}. International Journal of Computer Theory 
        and Engineering, Vol. 5 (6), págs. 856--860, 2013. 
    \bibitem{book2} M. Zaki y W. Meira. {\em Data minining and Analysis}. Cambridge University Press, 2014. 
    \bibitem{book1} G. James, D. Witten, T. Hastie y R. Tibshirani. {\em An Introduction to Statistical Learning}.
        Springer 2013.
    \bibitem{kmodes} Z.  Huang. {\em Clustering large data sets with mixed numeric and categorical values}. En Proceedings of the First Pacific Asia 
        Knowledge Discovery and Data Mining Conference, págs. 21--34, 1997.
    \bibitem{kuri} A. Kuri. {\em Categorical Encoding with Neural Networks and Genetic Algorithms}. Recent Researches in
        Applied Informatics: Proceedings of AICT '15, WSEAS Press, 2015.
    }
\end{thebibliography}
    \end{multicols}
\end{document}

