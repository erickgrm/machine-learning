{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento con reducción de dimensión con PCA\n",
    "Atributos del tipo likert se tratan como categóricos ordinales, se aplica one-hot-encoding a los datos categóricos y se reduce la dimensión del conjunto por medio de PCA.  Posteriormente se entrena:\n",
    "\n",
    "1. Un modelo por regresión logística\n",
    "2. Un modelo por máquinas de soporte vectorial\n",
    "\n",
    "En cada caso se selecciona un mejor modelo por validación cruzada.\n",
    "\n",
    "Iniciamos por cargar la base de datos (se remueven aquellos renglones en los que hay valores desconocidos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>house_val</th>\n",
       "      <th>age</th>\n",
       "      <th>online</th>\n",
       "      <th>customer_psy</th>\n",
       "      <th>marriage</th>\n",
       "      <th>child</th>\n",
       "      <th>occupation</th>\n",
       "      <th>mortgage</th>\n",
       "      <th>house_owner</th>\n",
       "      <th>region</th>\n",
       "      <th>car_prob</th>\n",
       "      <th>fam_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>3. Bach</td>\n",
       "      <td>248694</td>\n",
       "      <td>6upto65</td>\n",
       "      <td>Y</td>\n",
       "      <td>B</td>\n",
       "      <td>Married</td>\n",
       "      <td>N</td>\n",
       "      <td>Professional</td>\n",
       "      <td>2Med</td>\n",
       "      <td>Owner</td>\n",
       "      <td>West</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>3. Bach</td>\n",
       "      <td>416925</td>\n",
       "      <td>5upto55</td>\n",
       "      <td>Y</td>\n",
       "      <td>C</td>\n",
       "      <td>Married</td>\n",
       "      <td>Y</td>\n",
       "      <td>Professional</td>\n",
       "      <td>1Low</td>\n",
       "      <td>Owner</td>\n",
       "      <td>South</td>\n",
       "      <td>2</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>3. Bach</td>\n",
       "      <td>245686</td>\n",
       "      <td>4upto45</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>Married</td>\n",
       "      <td>U</td>\n",
       "      <td>Blue Collar</td>\n",
       "      <td>1Low</td>\n",
       "      <td>Owner</td>\n",
       "      <td>South</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Y</td>\n",
       "      <td>F</td>\n",
       "      <td>2. Some College</td>\n",
       "      <td>360587</td>\n",
       "      <td>5upto55</td>\n",
       "      <td>Y</td>\n",
       "      <td>C</td>\n",
       "      <td>Married</td>\n",
       "      <td>Y</td>\n",
       "      <td>Professional</td>\n",
       "      <td>3High</td>\n",
       "      <td>Owner</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>1</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Y</td>\n",
       "      <td>M</td>\n",
       "      <td>0. lessHS</td>\n",
       "      <td>162884</td>\n",
       "      <td>1_Unk</td>\n",
       "      <td>Y</td>\n",
       "      <td>G</td>\n",
       "      <td>Married</td>\n",
       "      <td>Y</td>\n",
       "      <td>Professional</td>\n",
       "      <td>1Low</td>\n",
       "      <td>Renter</td>\n",
       "      <td>South</td>\n",
       "      <td>7</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flag gender        education  house_val      age online customer_psy  \\\n",
       "5     Y      F          3. Bach     248694  6upto65      Y            B   \n",
       "7     N      F          3. Bach     416925  5upto55      Y            C   \n",
       "11    Y      F          3. Bach     245686  4upto45      N            F   \n",
       "12    Y      F  2. Some College     360587  5upto55      Y            C   \n",
       "15    Y      M        0. lessHS     162884    1_Unk      Y            G   \n",
       "\n",
       "   marriage child    occupation mortgage house_owner   region  car_prob  \\\n",
       "5   Married     N  Professional     2Med       Owner     West         1   \n",
       "7   Married     Y  Professional     1Low       Owner    South         2   \n",
       "11  Married     U   Blue Collar     1Low       Owner    South         3   \n",
       "12  Married     Y  Professional    3High       Owner  Midwest         1   \n",
       "15  Married     Y  Professional     1Low      Renter    South         7   \n",
       "\n",
       "   fam_income  \n",
       "5           G  \n",
       "7           I  \n",
       "11          E  \n",
       "12          J  \n",
       "15          C  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dF_pca = pd.read_csv(\"sales_data.csv\").dropna()\n",
    "dF_pca.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "Los valores de las columnas fam_income y car_prob (que son de tipo categórico ordinal) se convierten en númericos, \n",
    "bajo el supuesto de que valores más grandes son mejores. Se re-escalan las columnas house_val, \n",
    "fam_income y car_prob a $[0,1]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale house_val\n",
    "m, M = dF_pca.house_val.min(), dF_pca.house_val.max()\n",
    "dF_pca['house_val'] = (dF_pca.house_val - m) / (M - m)\n",
    "\n",
    "# Rescale car_prob\n",
    "dF_pca['car_prob'] = dF_pca.car_prob / 10\n",
    "\n",
    "# Change categorical ordinal values to numbers\n",
    "for i in range(0,len(dF_pca)):\n",
    "    if dF_pca.iloc[i,14] == 'U': dF_pca.iloc[i,14] = 0\n",
    "    if dF_pca.iloc[i,14] == 'A': dF_pca.iloc[i,14] = 0\n",
    "    if dF_pca.iloc[i,14] == 'B': dF_pca.iloc[i,14] = 1\n",
    "    if dF_pca.iloc[i,14] == 'C': dF_pca.iloc[i,14] = 2\n",
    "    if dF_pca.iloc[i,14] == 'D': dF_pca.iloc[i,14] = 3\n",
    "    if dF_pca.iloc[i,14] == 'E': dF_pca.iloc[i,14] = 4\n",
    "    if dF_pca.iloc[i,14] == 'F': dF_pca.iloc[i,14] = 5\n",
    "    if dF_pca.iloc[i,14] == 'G': dF_pca.iloc[i,14] = 6\n",
    "    if dF_pca.iloc[i,14] == 'H': dF_pca.iloc[i,14] = 7\n",
    "    if dF_pca.iloc[i,14] == 'I': dF_pca.iloc[i,14] = 8\n",
    "    if dF_pca.iloc[i,14] == 'J': dF_pca.iloc[i,14] = 9\n",
    "    if dF_pca.iloc[i,14] == 'K': dF_pca.iloc[i,14] = 10\n",
    "    if dF_pca.iloc[i,14] == 'L': dF_pca.iloc[i,14] = 11\n",
    "dF_pca.head(5)\n",
    "\n",
    "# Rescale fam_income\n",
    "dF_pca['fam_income'] = dF_pca.fam_income / 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos one-hot-encoding para todos los valores que aún no son númericos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de aributos tiene dimensiones:  23558 x 51\n"
     ]
    }
   ],
   "source": [
    "# Encoding\n",
    "dF_pca = pd.get_dummies(dF_pca)\n",
    "\n",
    "# Separate response column and atributes matrix\n",
    "y_pca = dF_pca['flag_Y'].values\n",
    "X_pre = dF_pca.drop(['flag_N','flag_Y'], axis =1).values\n",
    "print(\"Matriz de aributos tiene dimensiones: \",  len(X_pre), \"x\",len(X_pre[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "Aplicamos Análisis de Componentes Principales (PCA), reteniendo aquellas columnas que explican al menos el 85% de la varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducción de  51  a  20 dimensiones (atributos)\n",
      "Porcentages de varianza explicada por cada una de las 23 dimensiones conservadas:\n",
      "  [12.89199597  8.32043749  7.13981809  5.46342494  4.92277369  4.72399807\n",
      "  4.43113687  4.00147842  3.75092964  3.55956291  3.25409463  3.06330768\n",
      "  2.92005829  2.79515602  2.77087799  2.36219632  2.34734231  2.27746684\n",
      "  2.19785328  2.00314455]\n"
     ]
    }
   ],
   "source": [
    "# Import PCA module and instantiate a PCA object\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.85)\n",
    "\n",
    "# Apply pca to atributes matrix \n",
    "pca.fit(X_pre)\n",
    "var_ratios = pca.explained_variance_ratio_\n",
    "print(\"Reducción de \", len(X_pre[0]), \" a \", len(var_ratios), \"dimensiones (atributos)\")\n",
    "print(\"Porcentages de varianza explicada por cada una de las 23 dimensiones conservadas:\\n \", var_ratios*100)\n",
    "\n",
    "# Reduced atributes matrix\n",
    "X_pca = pca.transform(X_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logramos reducir las dimensiones de la matriz de atributos de 51 columnas a 20 columnas. X_pca es la matriz resultante de recodificar la matriz de atributos original después de aplicar PCA. Ahora pasamos a entrenar los modelos propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística\n",
    "Con X_pca y y_pca ahora obtenemos un modelo por regresión logística. La elección del modelo se hace por 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scikit-learn modules and generate instance of regression model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "logistic_reg = LogisticRegressionCV(cv = 10, random_state = 1, max_iter = 150)\n",
    "\n",
    "# Train model on X and y, and automatically select best after cross-validation\n",
    "logreg_model = logistic_reg.fit(X_pca, y_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes del modelo: \n",
      " [[-0.90101765 -0.33823284  0.42624811  0.52350282 -0.16222863  0.25723397\n",
      "   0.33603964  0.07502424  0.06074424 -0.10480025  0.20623918 -0.01608479\n",
      "  -0.0745244   0.11378817 -0.03765142  0.12189565  0.19245644  0.02074486\n",
      "  -0.27067891 -0.05363118]]\n",
      "Score sobre el conjunto de datos completo: 69.23762628406486\n",
      "Cualidades de la clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.59      0.62     10219\n",
      "           1       0.71      0.77      0.74     13339\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     23558\n",
      "   macro avg       0.69      0.68      0.68     23558\n",
      "weighted avg       0.69      0.69      0.69     23558\n",
      "\n",
      "Matriz de confusión:\n",
      " [[ 6031  4188]\n",
      " [ 3059 10280]]\n"
     ]
    }
   ],
   "source": [
    "# Details of the model\n",
    "print(\"Coeficientes del modelo: \\n\", logreg_model.coef_)\n",
    "print(\"Score sobre el conjunto de datos completo:\", logreg_model.score(X_pca,y_pca)*100)\n",
    "\n",
    "# Quality of the model\n",
    "y_pca_pred = logreg_model.predict(X_pca)\n",
    "print(\"Cualidades de la clasificación:\\n\", classification_report(y_pca, y_pca_pred))\n",
    "print(\"Matriz de confusión:\\n\", confusion_matrix(y_pca, y_pca_pred,labels = range(2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Máquinas de soporte vectorial (SVM)\n",
    "Con X_pca y y_pca obtenemos un modelo por SVMs. En la selección del modelo evaluamos modelos con diferentes coeficientes de regularización C y gama, y evaluamos con 5fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n"
     ]
    }
   ],
   "source": [
    "# Import scikit-learn modules\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca, y_pca, test_size=0.30, random_state=1)\n",
    "\n",
    "# SLOW!!!\n",
    "# Find best SVM model through 5fold cv and grid search, radial kernel\n",
    "grid = {'C': [1, 10, 100], 'gamma': [0.01, 0.05, 0.1], } #{'C': [1, 10, 100], 'gamma': [0.005, 0.01, 0.1], }\n",
    "svm_model = GridSearchCV(SVC(kernel='rbf'), grid, cv=2, iid=False)\n",
    "\n",
    "svm_model = svm_model.fit(X_pca_train, y_pca_train)\n",
    "print(\"Best estimator found by grid search:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(svm_model.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
