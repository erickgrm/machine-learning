{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Import own libraries with custom technical routines and own implementation of logistic regression\n",
    "from custom_routines import custom_routines as cr\n",
    "from logisticReg import logistic_regression\n",
    "\n",
    "# Import Naive Bayes classifiers from sci-kit learn\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clasificación de spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n",
      "3620 1552\n"
     ]
    }
   ],
   "source": [
    "spam_data = pd.read_csv(\"~/Desktop/mcc20192/mlearning/tareas/tarea3/data/spam.csv\", header=None, delimiter=\" \").values\n",
    "print(len(spam_data))\n",
    "#Partición aleatoria del conjunto de datos, 70% para entrenamiento y 30% para validación\n",
    "train_spam_data, test_spam_data = train_test_split(spam_data, test_size=0.30, random_state=0)\n",
    "print(len(train_spam_data),len(test_spam_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541436464088398\n",
      "0.9478092783505154\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'areauc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-17ec98ec39c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mareaucmulti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpmulti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpmulti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Área bajo la curva ROC =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mareauc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'areauc' is not defined"
     ]
    }
   ],
   "source": [
    "multinomial_classifier = MultinomialNB()\n",
    "\n",
    "multinomial_classifier.fit(train_spam_data[0:,:-1], train_spam_data[0:,-1])\n",
    "print(multinomial_classifier.score(train_spam_data[0:,:-1], train_spam_data[0:,-1]))\n",
    "print(multinomial_classifier.score(test_spam_data[0:,:-1], test_spam_data[0:,-1]))\n",
    "m = len(test_spam_data)\n",
    "mpred = multinomial_classifier.predict(test_spam_data[0:,:-1])\n",
    "fpmulti = dict()\n",
    "tpmulti = dict()\n",
    "areaucmulti= dict()\n",
    "\n",
    "for i in range(0,m):\n",
    "    fpmulti[i], tpmulti[i], _ = roc_curve(test_spam_data[0:,-1], mpred)\n",
    "    areaucmulti[i] = auc(fpmulti[i], tpmulti[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpmulti[\"micro\"], tpmulti[\"micro\"], _ = roc_curve(test_spam_data[0:,-1].ravel(), mpred.ravel())#  y_test.ravel(), y_score.ravel())\n",
    "areaucmulti[\"micro\"] = auc(fpmulti[\"micro\"], tpmulti[\"micro\"])\n",
    "\n",
    "print(\"Área bajo la curva ROC =\", areauc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8656f4c3fd6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlogit_reg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogit_reg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_spam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_spam_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/mcc20192/mlearning/tareas/tarea3/logisticReg.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, features, responses, lambd)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Find optimal vector of weights through the gradient descend algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgd_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgdE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mcc20192/mlearning/tareas/tarea3/logisticReg.py\u001b[0m in \u001b[0;36mgd_minimize\u001b[0;34m(self, gdf, theta0, alpha, error)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mtheta_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_min\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0miter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtheta_min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/mcc20192/mlearning/tareas/tarea3/logisticReg.py\u001b[0m in \u001b[0;36mgdE\u001b[0;34m(self, theta)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# The gradient of the loss function, general to accept l2 regularization with parameter lambd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgdE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mdtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdtheta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train logistic regression \n",
    "logit_reg1 = logistic_regression()\n",
    "logit_reg1.fit(train_spam_data[0:,:-1],train_spam_data[0:,-1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_reg1.score(train_spam_data[0:,:-1],train_spam_data[0:,-1]))\n",
    "print(logit_reg1.score(test_spam_data[0:,:-1],test_spam_data[0:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and area under \n",
    "logit_reg1_predicted = logit_reg1.predict(test_spam_data[0:,:-1])\n",
    "\n",
    "falsepositive = dict()\n",
    "truepositive = dict()\n",
    "areauc= dict()\n",
    "\n",
    "for i in range(0,m):\n",
    "    falsepositive[i], truepositive[i], _ = roc_curve(test_spam_data[0:,-1], logit_reg1_predicted)\n",
    "    areauc[i] = auc(falsepositive[i], truepositive[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "falsepositive[\"micro\"], truepositive[\"micro\"], _ = roc_curve(test_spam_data[0:,-1].ravel(), logit_reg1_predicted.ravel())#  y_test.ravel(), y_score.ravel())\n",
    "areauc[\"micro\"] = auc(falsepositive[\"micro\"], truepositive[\"micro\"])\n",
    "\n",
    "print(\"Área bajo la curva ROC =\", areauc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Curva ROC para logit_reg1')\n",
    "plt.plot(falsepositive[2], truepositive[2], color='darkorange', label='Logistic ROC')\n",
    "plt.plot(fpmulti[2], tpmulti[2], color='navy', label='MultinomialNB ROC')\n",
    "plt.plot(0,0,'ko', label = 'Área Regresión Logit ~ %0.2f' % areauc[2])\n",
    "plt.plot(0,0,'bo', label = 'Área MultinomialNB ~ %0.2f' % areaucmulti[2])\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Proporción de Falsos Positivos')\n",
    "plt.ylabel('Proporción de Verdaderos Positivos')\n",
    "\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clasificación de tumores de seno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data_raw = pd.read_csv(\"~/Desktop/mcc20192/mlearning/tareas/tarea3/data/breast-cancer-wisconsin.data\", header=None).values[0:,1:]\n",
    "print(cancer_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sustituir valores desconocidos por 0 y cambiar las etiquetas por 0 y 1\n",
    "n = len(cancer_data_raw)\n",
    "l = len(cancer_data_raw[0])\n",
    "cancer_data = np.ndarray(shape = (n,l))\n",
    "type(cancer_data[0][0])\n",
    "\n",
    "for i in range(0, n):\n",
    "    for j in range(0, l-1):\n",
    "        if cancer_data_raw[i][j] == '?':\n",
    "            cancer_data[i][j] = 0\n",
    "        else:\n",
    "            cancer_data[i][j] = int(cancer_data_raw[i][j])\n",
    "    cancer_data[i][-1] = int(cancer_data_raw[i][-1]/2 -1)\n",
    "\n",
    "print(cancer_data)\n",
    "\n",
    "#Partición aleatoria del conjunto de datos, 70% para entrenamiento y 30% para validación\n",
    "train_cancer_data, test_cancer_data = train_test_split(cancer_data, test_size = 0.30, random_state=3)\n",
    "print(len(train_cancer_data),len(test_cancer_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_classifier = GaussianNB()\n",
    "\n",
    "# Entrenamos el clasificador\n",
    "print(gaussian_classifier.fit(train_cancer_data[0:,:-1], train_cancer_data[0:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_classifier.score(test_cancer_data[0:,:-1],test_cancer_data[0:,-1])\n",
    "gpred = gaussian_classifier.predict(test_cancer_data[0:,:-1])\n",
    "gpred\n",
    "\n",
    "fpgauss = dict()\n",
    "tpgauss = dict()\n",
    "areaucgauss = dict()\n",
    "for i in range(0,len(test_cancer_data)):\n",
    "    fpgauss[i], tpgauss[i], _ = roc_curve(test_cancer_data[0:,-1], gpred)\n",
    "    areaucgauss[i] = auc(fpgauss[i], tpgauss[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpgauss[\"micro\"], tpgauss[\"micro\"], _ = roc_curve(test_cancer_data[0:,-1].ravel(), gpred.ravel())#  y_test.ravel(), y_score.ravel())\n",
    "areaucgauss[\"micro\"] = auc(fpgauss[\"micro\"], tpgauss[\"micro\"])\n",
    "\n",
    "print(\"Área bajo la curva ROC =\", areaucgauss[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression \n",
    "logit_reg2 = logistic_regression()\n",
    "logit_reg2.fit(train_cancer_data[0:,:-1], train_cancer_data[0:,-1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_reg2.score(train_cancer_data[0:,:-1], train_cancer_data[0:,-1]))\n",
    "print(logit_reg2.score(test_cancer_data[0:,:-1], test_cancer_data[0:,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and area under \n",
    "logit_reg2_predicted = logit_reg2.predict(test_cancer_data[0:,:-1])\n",
    "\n",
    "falsepositive2 = dict()\n",
    "truepositive2 = dict()\n",
    "areauc2 = dict()\n",
    "for i in range(0,len(test_cancer_data)):\n",
    "    falsepositive2[i], truepositive2[i], _ = roc_curve(test_cancer_data[0:,-1], logit_reg2_predicted)\n",
    "    areauc2[i] = auc(falsepositive2[i], truepositive2[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "falsepositive2[\"micro\"], truepositive2[\"micro\"], _ = roc_curve(test_cancer_data[0:,-1].ravel(), logit_reg2_predicted.ravel())#  y_test.ravel(), y_score.ravel())\n",
    "areauc2[\"micro\"] = auc(falsepositive2[\"micro\"], truepositive2[\"micro\"])\n",
    "\n",
    "print(\"Área bajo la curva ROC =\", areauc2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Curvas ROC')\n",
    "plt.plot(falsepositive2[2], truepositive2[2], color='darkorange', label='Logistic ROC')\n",
    "plt.plot(fpgauss[2], tpgauss[2], color='navy', label='GaussianNB ROC')\n",
    "plt.plot(0,0,'ko', label = 'Área Regresión Logit ~ %0.2f' % areauc2[2])\n",
    "plt.plot(0,0,'ko', label = 'Área GaussianNB ~ %0.2f' % areaucgauss[2])\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Proporción de Falsos Positivos')\n",
    "plt.ylabel('Proporción de Veraderos Positivos')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#for i in range(0,10):\n",
    "#    train_data, test_data= train_test_split(data_enc, test_size=0.30, random_state=3*i)\n",
    "#    clf = LogisticRegression(C = 100, random_state=0, fit_intercept = False, solver='lbfgs', multi_class='ovr').fit(train_data[0:,:-1], train_data[0:,-1])\n",
    "#    print(clf.score(test_data[0:,:-1], test_data[0:,-1]))#data_enc[0:,:-1], data_enc[0:,-1])\n",
    "clf = LogisticRegression(C = 100, random_state=0, fit_intercept = False, solver='lbfgs', multi_class='ovr').fit(train_cancer_data[0:,:-1], train_cancer_data[0:,-1])\n",
    "pred = clf.predict(test_cancer_data[0:,:-1])\n",
    "\n",
    "falsepositive3 = dict()\n",
    "truepositive3 = dict()\n",
    "areauc3 = dict()\n",
    "for i in range(0,len(test_cancer_data)):\n",
    "    falsepositive3[i], truepositive3[i], _ = roc_curve(test_cancer_data[0:,-1], pred)\n",
    "    areauc3[i] = auc(falsepositive3[i], truepositive3[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "falsepositive3[\"micro\"], truepositive3[\"micro\"], _ = roc_curve(test_cancer_data[0:,-1].ravel(), pred.ravel())#  y_test.ravel(), y_score.ravel())\n",
    "areauc2[\"micro\"] = auc(falsepositive3[\"micro\"], truepositive3[\"micro\"])\n",
    "\n",
    "print(\"Área bajo la curva ROC =\", areauc3[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Curva ROC para sklearn-clf')\n",
    "plt.plot(falsepositive3[2], truepositive3[2], color='darkorange', label='Curva ROC')\n",
    "plt.plot(0,0,'ko', label = 'Área bajo la curva ~ %0.2f' % areauc3[2])\n",
    "plt.plot([0, 1], [0, 1], color='blue', linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
