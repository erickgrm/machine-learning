{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1>Problema 4: Cáncer de seno</h1>\n",
    "<p>Autor: Erick García Ramírez<br /> \n",
    "erick_phy@ciencias.unam.mx<br /> \n",
    "Curso de Aprendizaje Automatizado, MCIC 2019-2</p>\n",
    "\n",
    "<h2>Introducción</h2>\n",
    "<p> Buscamos entrenar dos clasificadores para predecir si un tumor, dada su lista de atributos, es maligno o benigno.  En este problema tenemos que lidiar con el desconocimiento de algunos valores de atributos. En el archivo <em>breast-cancer-winconsin.data</em> la ausencia del valor de un atributo se marca con '?'.  Ahondaremos más adelante en este problema; por el momento, basta mencionar brevemente dos propuestas para tratarlo:\n",
    "<ol>\n",
    "<li> Reemplazar cada atributo desconocido  por la media calculada sobre todos los valores de dicho atributo (promedio sobre la columna en la que está el valor desconocido). </li>\n",
    "<li> Ignorar dichos casos. Esto esencialmente corresponde a reemplazar cada valor faltante por un 0.</li>\n",
    "</ol>\n",
    "    \n",
    "Se usará la biblioteca scikit-learn para entrenar dos clasificadores, además de que usaremos las bibliotecas usuales (numpy y pandas). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import  BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> En la siguiente celda cargamos los datos en <em>breast-cancer-winconsin.data</em> y presentamos los histogramas para cada uno de los 9 atributos de tumores. Dichos histogramas nos permiten observar que las distribuciones de los atributos no son simétricos, y que en general no siguen una distribución normal. De esta observación proponemos usar los clasificadores BernoulliNB y MultinomialNB (de scikit-learn) para el presente problema. En la opinión del autor, las distribuciones de los 9 atributos (quizás con excepción del segundo) parecen tener una distribución exponencial. Lamentablemente no encontramos alguna herramienta en scikit-learn para trabajar con dicha distribución (identificamos a expon de la librería scipy.stats, pero consideramos que su uso rebasaa el alcance y nivel de la presente tarea)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0d246438>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c4dff98>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c491358>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c4b68d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c45fe48>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c410400>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c436978>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c3def28>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f5a0c3def60>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"~/Desktop/mcc20192/mlearning/tareas/tarea2/nb_data/breast-cancer-wisconsin.data\", header=None)\n",
    "pd.DataFrame.hist(data.iloc[0:,:-1], grid=False,bins=30,figsize=(14,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, creamos el arreglo data_matrix con todos los valores de atributos y etiquetas. Seguidamente, con la función train_test_split partimos los datos en data_matrix en un conjunto de datos para entrenamiento (train_data) y otro de datos para validación (test_data). La proporción del primero contra el segundo es de 70% contra 30% de los datos totales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524 175\n"
     ]
    }
   ],
   "source": [
    "data_matrix = data.values[0:,1:]\n",
    "\n",
    "# Partición aleatoria del conjunto de datos, proporción 70% vs 30%\n",
    "train_data, test_data= train_test_split(data_matrix, test_size=0.30, random_state=0)\n",
    "# Imprimimos las cardinalidades de ambos conjuntos\n",
    "print(len(train_data),len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primer función en la siguiente celda calcula las medias de cada columna de atributo en data_matrix, y la segunda función es una rutina para reemplazar las entradas desconocidas en una matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de las medias por columna de una matriz\n",
    "def vector_of_experimental_means(matrix):\n",
    "    means = np.zeros(9)\n",
    "    for j in range(0,9):\n",
    "        known_count = 0\n",
    "        s = 0    \n",
    "        for i in range(0,len(matrix)):\n",
    "            if matrix[i][j] != '?':\n",
    "                s += int(matrix[i][j])\n",
    "                known_count += 1\n",
    "            means[j] = s/known_count\n",
    "    return means\n",
    "\n",
    "# Reemplazo de atributos desconocidos por los valores del vector v; v será el vector de medias o un vector con todas sus entradas = 0\n",
    "def replace_unknown(matrix,v):\n",
    "    for i in range(0,len(matrix)):\n",
    "        for j in range(0,8):\n",
    "            if matrix[i][j] == '?':\n",
    "                matrix[i][j] = v[j]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de este momento seguiremos la propuesta de sustituir un valor desconocido en la columna j por la media global de dicha columna. Así, primero calculamos el vector de medias globales (i.e. de data_matrix). Posteriormente, separamos el conjunto de entrenamiento en una matriz de atributos (train_matrix) y el vector correspondiente de etiquetas (train_labels). Hacemos lo análogo para el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El vector de medias para data_matrix\n",
    "means = vector_of_experimental_means(data_matrix[0:,0:-1])\n",
    "\n",
    "# Preparación del conjunto de entrenamiento con reemplazo de atributos desconocidos por medias\n",
    "train_matrix = replace_unknown(train_data[0:,0:-1],means)\n",
    "train_labels = train_data[0:,-1]\n",
    "train_labels=train_labels.astype('int')\n",
    "\n",
    "# Preparación del conjunto de validación con reemplazo de atributos desconocidos por medias\n",
    "test_matrix = replace_unknown(test_data[0:,0:-1],means)\n",
    "test_labels = test_data[0:,-1]\n",
    "test_labels=test_labels.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clasificadores y su entrenamiento </h1>\n",
    "Ahora entrenamos los clasificadores propuestos, BernoulliNB y MultinomialNB. También entrenamos GaussianNB sólo para comparar; recuerde que le \n",
    "habíamos descartado ya que los atributos no parecen seguir una distribución gaussiana. Recuerde que por el momento hemos reemplazado los valores desconocidos de atributos por las medias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=1.0, class_prior=None, fit_prior=True)\n",
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n"
     ]
    }
   ],
   "source": [
    "# Proponemos los siguientes dos clasificadores\n",
    "bernoulli_classifier = BernoulliNB(binarize = 1.0)\n",
    "multinomial_classifier = MultinomialNB()\n",
    "\n",
    "# Sugerimos GaussianNB para hacer comparaciones\n",
    "normal_classifier = GaussianNB()\n",
    "\n",
    "# Entrenamos los clasificadores\n",
    "print(bernoulli_classifier.fit(train_matrix,train_labels))\n",
    "print(multinomial_classifier.fit(train_matrix,train_labels))\n",
    "print(normal_classifier.fit(train_matrix,train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIÓN AUXILIAR: tomada de  https://gist.github.com/zachguo/10296432\n",
    "# Autor: zachguo\n",
    "# Esta función sirve para imprimir la matriz de confusión\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()\n",
    "        \n",
    "# FUNCIÓN AUXILIAR: Función para calcular el número de errores de clasificación\n",
    "def classification_errors(predicted,real):\n",
    "    s = 0\n",
    "    for i in range(0,len(predicted)):\n",
    "        if predicted[i] != real[i]:\n",
    "            s += 1\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rendimiento</h1>\n",
    "Ahora damos un vistazo al rendimiento de los clasificadores entrenados. En la celda debajo lo hacemos para el conjunto de datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOBRE EL CONJUNTO DE ENTRENAMIENTO.\n",
      "Matriz de confusión para BernoulliNB:\n",
      "            benigno maligno \n",
      "    benigno   321.0     2.0 \n",
      "    maligno    25.0   176.0 \n",
      "Número de errores para BernoulliNB: 27\n",
      "Porcentaje de aciertos: 94.85\n",
      "\n",
      "Matriz de confusión para MutinomialNB:\n",
      "            benigno maligno \n",
      "    benigno   325.0    39.0 \n",
      "    maligno    21.0   139.0 \n",
      "Número de errores para MultinomialNB: 60\n",
      "Porcentaje de aciertos: 88.55\n",
      "\n",
      "Matriz de confusión para GaussianNB:\n",
      "            benigno maligno \n",
      "    benigno   330.0     3.0 \n",
      "    maligno    16.0   175.0 \n",
      "Número de errores  para GaussianNB: 19\n",
      "Porcentaje de aciertos: 96.37\n"
     ]
    }
   ],
   "source": [
    "# Pruebas en el conjunto de entrenamiento\n",
    "predict_train_bernoulli = bernoulli_classifier.predict(train_matrix)\n",
    "predict_train_multinomial = multinomial_classifier.predict(train_matrix)\n",
    "predict_train_normal = normal_classifier.predict(train_matrix)\n",
    "\n",
    "print('SOBRE EL CONJUNTO DE ENTRENAMIENTO.')\n",
    "# Desempeño de BernoulliNB\n",
    "e=classification_errors(predict_train_bernoulli,train_labels)\n",
    "print('Matriz de confusión para BernoulliNB:')\n",
    "print_cm(confusion_matrix(predict_train_bernoulli, train_labels),['benigno','maligno'])\n",
    "print('Número de errores para BernoulliNB:', e)\n",
    "print('Porcentaje de aciertos:', round(100*(len(train_matrix)-e)/len(train_matrix),2))\n",
    "print()\n",
    "# Desempeño de MultinomialNB\n",
    "print('Matriz de confusión para MutinomialNB:')\n",
    "e=classification_errors(predict_train_multinomial,train_labels)\n",
    "print_cm(confusion_matrix(predict_train_multinomial, train_labels),['benigno','maligno'])\n",
    "print('Número de errores para MultinomialNB:', classification_errors(predict_train_multinomial,train_labels))\n",
    "print('Porcentaje de aciertos:', round(100*(len(train_matrix)-e)/len(train_matrix),2))\n",
    "print()\n",
    "# Desempeño de GaussianNB\n",
    "print('Matriz de confusión para GaussianNB:')\n",
    "e=classification_errors(predict_train_normal,train_labels)\n",
    "print_cm(confusion_matrix(predict_train_normal, train_labels),['benigno','maligno'])\n",
    "print('Número de errores  para GaussianNB:', classification_errors(predict_train_normal,train_labels))\n",
    "print('Porcentaje de aciertos:', round(100*(len(train_matrix)-e)/len(train_matrix),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora presentamos el rendimiento de los clasificadores sobre el conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOBRE EL CONJUNTO DE VALIDACIÓN.\n",
      "Matriz de confusión para BernoulliNB:\n",
      "            benigno maligno \n",
      "    benigno    98.0     1.0 \n",
      "    maligno    14.0    62.0 \n",
      "Número de errores para BernoulliNB: 15\n",
      "Porcentaje de aciertos: 91.43\n",
      "\n",
      "Matriz de confusión para MutinomialNB:\n",
      "            benigno maligno \n",
      "    benigno   105.0    16.0 \n",
      "    maligno     7.0    47.0 \n",
      "Número de errores para MultinomialNB: 23\n",
      "Porcentaje de aciertos: 86.86\n",
      "\n",
      "Matriz de confusión para GaussianNB:\n",
      "            benigno maligno \n",
      "    benigno   106.0     2.0 \n",
      "    maligno     6.0    61.0 \n",
      "Número de errores  para GaussianNB: 8\n",
      "Porcentaje de aciertos: 95.43\n"
     ]
    }
   ],
   "source": [
    "# Pruebas en el conjunto de validación\n",
    "predict_test_bernoulli = bernoulli_classifier.predict(test_matrix)\n",
    "predict_test_multinomial = multinomial_classifier.predict(test_matrix)\n",
    "predict_test_normal = normal_classifier.predict(test_matrix)\n",
    "\n",
    "print('SOBRE EL CONJUNTO DE VALIDACIÓN.')\n",
    "# Desempeño de BernoulliNB\n",
    "e=classification_errors(predict_test_bernoulli,test_labels)\n",
    "print('Matriz de confusión para BernoulliNB:')\n",
    "print_cm(confusion_matrix(predict_test_bernoulli, test_labels),['benigno','maligno'])\n",
    "print('Número de errores para BernoulliNB:', e)\n",
    "print('Porcentaje de aciertos:', round(100*(len(test_matrix)-e)/len(test_matrix),2))\n",
    "print()\n",
    "# Desempeño de MultinomialNB\n",
    "print('Matriz de confusión para MutinomialNB:')\n",
    "e=classification_errors(predict_test_multinomial,test_labels)\n",
    "print_cm(confusion_matrix(predict_test_multinomial, test_labels),['benigno','maligno'])\n",
    "print('Número de errores para MultinomialNB:', classification_errors(predict_test_multinomial,test_labels))\n",
    "print('Porcentaje de aciertos:', round(100*(len(test_matrix)-e)/len(test_matrix),2))\n",
    "print()\n",
    "# Desempeño de GaussianNB\n",
    "print('Matriz de confusión para GaussianNB:')\n",
    "e=classification_errors(predict_test_normal,test_labels)\n",
    "print_cm(confusion_matrix(predict_test_normal, test_labels),['benigno','maligno'])\n",
    "print('Número de errores  para GaussianNB:', classification_errors(predict_test_normal,test_labels))\n",
    "print('Porcentaje de aciertos:', round(100*(len(test_matrix)-e)/len(test_matrix),2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusiones </h1>\n",
    "Curiosamente, el clasificador GaussianNB tiene un mejor rendimiento que los otros dos. Entre los dos propuestos, BernoulliNB es mejor que MultinomialNB, con cerca de 5% más aciertos sobre ambos conjuntos de entrenamiento y de validación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Reemplazo de valores desconocidos por 0's</h3>\n",
    "Brevemente, ahora mencionamos qué pasa cuando reemplazamos por 0 los valores desconocidos. Tratamos con diferentes semillas (el valor de random_state en train_test_split(data_matrix, test_size=0.30, random_state=0)), es decir, con diferentes particiones de los datos, y no encontramos diferencias en el rendimiento de los clasificadores. Hay dos posibles razones para esto: a) los valores desconocidos son pocos y  por lo tanto no influyen, y/o b) como los valores desconocidos pertecen a la misma columna, es posible suponer que el atributo en esa columna no es significativo para la clasificación. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
